---
title: "Working With AI"
date: 2026-02-03T16:30
type: note
schemaVersion: 1
draft: false
description: "How I think with AI, where I don't trust it, and what co-authorship means."
tags:
  - ai
heroImage: /images/posts/working-with-ai-hero.png
---

I use AI to build and write. Not sometimes—daily. Claude, ChatGPT, local models when they make sense. It's part of my workflow the same way Git or VS Code is.

I'm not going to walk you through my setup. You can find a thousand posts about using AI for scaffolding, refactoring, research, and drafting. They all say roughly the same thing, and they're all roughly correct.

What I want to talk about is what surprised me.

---

I spent a decade building judgment. Learning which abstractions hold up and which collapse under pressure. Developing a feel for when code is clean and when it's just tidy. Figuring out what to build, not just how to build it.

For most of that decade, I couldn't fully use that judgment because I was also doing the typing. The boilerplate, the plumbing, the conversion of decisions into syntax. The strategic layer and the execution layer were fused, and execution ate most of the clock.

AI split them apart.

I thought this would feel like a loss — less hands-on, less craft, more management. It feels like the opposite. It feels like being promoted to creative director of my own work.

A director doesn't operate the camera, but the film is still theirs. They set the vision, make the calls, decide what works and what gets cut. The craft is in the judgment, not the execution.

I'm not writing less. I'm deciding more. What to build, what's good enough, what needs to be scrapped, what the thing is actually *about*. And I like that work more than I liked grinding through implementation details.

I spent a decade building the instincts to make those calls. Now I actually get to use them.

Not everyone will feel this way. Some people love the execution itself — the satisfaction of a clean implementation, the meditative quality of code flowing from your hands. That's real. But for me, the shift has been a relief, not a compromise.

---

Here's what I've learned not to trust.

AI optimizes for coherence, not resonance. Left alone, it produces smooth, forgettable prose — the written equivalent of stock photography. Everything is correct and nothing is alive. You have to fight it constantly to keep your voice, your edges, the specific roughness that makes writing sound like a person instead of a summary.

It doesn't know when something is a bad idea. It will confidently scaffold the wrong abstraction if that's what the pattern suggests. It has no taste — or rather, it has consensus taste, which is worse than no taste because it's harder to detect.

And it doesn't share consequences. If I ship code that breaks production, that's on me. If I publish an idea that's wrong, that's on me. The tool is irrelevant. The accountability isn't.

Before anything goes out, I ask one question: would I defend this in a room full of people who know what they're talking about? If the answer is no, it doesn't ship. Doesn't matter who wrote which sentence.

---

Some of my posts list an AI as co-author. That means the AI meaningfully shaped the output — proposed framings I wouldn't have reached alone, suggested structures that survived into the final piece. It doesn't mean I typed a prompt and hit publish.

The thinking is mine. I stand behind every word.

I mark the contribution because I think hiding it would be worse than any discomfort the label creates.

But the co-authorship question is less interesting than the one underneath it: if AI can generate infinite content, why write at all?

Not for information. AI synthesizes that on demand. The how-to post, the explainer, the consensus overview — those are commodities now.

What's left is testimony. Someone with a name, a history, and real stakes saying: I believe this, and here's why.

The value isn't in the information. It's in the fact that a specific person is willing to attach their credibility to it. It's situated — my view from *somewhere*, shaped by particular experiences, carrying actual risk if I'm wrong.
