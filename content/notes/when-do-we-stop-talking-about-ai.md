---
title: "When Do We Stop Talking About AI?"
description: "Every disruptive technology eventually becomes invisible. Electricity did. The internet did. When does AI stop being 'AI' and just become... how things work?"
date: 2026-02-07T17:00
type: note
schemaVersion: 1
draft: false
heroImage: /images/posts/when-stop-talking-ai-hero.png
tags:
  - ai
  - technology
  - history
tension: "We're drowning in AI discourse. When does that end?"
---

I'm tired.

Not of AI — of *talking* about AI. The think pieces. The existential threads. The "everything will change" proclamations followed by the "nothing has changed" rebuttals. The breathless announcements and the weary corrections. The discourse.

You're tired too, right? I can tell because you clicked on a piece called "When Do We Stop Talking About AI?" hoping someone would give you permission to stop.

Here's what I keep coming back to: every disruptive technology eventually becomes invisible. The discourse ends. The modifier drops. The thing that was going to "change everything" just becomes... everything.

So when does that happen with AI? I'm genuinely not sure. But I have some guesses.

## The Exhaustion Is the Tell

Right now we're stuck in a weird loop — and if you've been paying attention, you've probably felt it:

**The existential spiral:** "AI will take my job" → "No wait, AI makes me more productive" → "But if everyone's more productive, fewer people are needed" → "But new jobs will emerge" → "Will they though?" → repeat

**The capability whiplash:** "Look what AI can do!" → "Actually it's wrong half the time" → "The new model is way better" → "Still hallucinates though" → "But it's improving exponentially" → repeat

**The vibe shift:** "AI is going to be amazing" → "AI is going to be terrifying" → "AI is overhyped" → "AI is underhyped" → "I don't know what to think anymore"

The exhaustion isn't a bug — it's a feature. It's how discourse dies. We don't stop talking about technologies because we've resolved the debates. We stop because we're tired of having them.

That's kind of sad, actually. But maybe also liberating?

## The Noise vs The Signal

Here's my confession: I'm still going to write about AI. A lot. This piece isn't "I'm done" — it's me trying to understand my own exhaustion.

**What I'm tired of:**
- "10 prompts that will change your life"
- LinkedIn thought leaders discovering ChatGPT
- Breathless hype from people selling shovels
- Doomer vs boomer discourse that generates heat but no light
- The outrage cycle (AI bad → AI overhyped → AI actually good → AI stealing jobs → repeat)
- Marketing disguised as insight

**What I'm not tired of:**
- Actually building with it
- Thinking through what it means for craft
- The real patterns emerging — how constraints shape AI interfaces, how judgment becomes the scarce resource, how photography and code face the same questions about what humans are still for
- Watching an entire industry restructure in real-time
- The genuinely weird philosophical questions (what is creativity? what is understanding? what are we?)

I find it both fascinating and tiring. Interesting and trite. The technology is legitimately transformative; the discourse around it is mostly noise.

Maybe that's always true during a transition? The signal-to-noise ratio is terrible precisely because everyone's trying to figure it out at once. The good thinking is buried under mountains of "Top 10 AI Tools for Productivity."

Does that resonate, or is it just me?

## The Half-Life of Disruption

Every previous technology wave followed this pattern:

**Electricity:** ~30 years. The 1880s were full of "electric" everything — electric lights, electric motors, electric appliances. People worried about electrocution, job displacement, the transformation of factories. By the 1920s, electricity was just infrastructure. You didn't advertise "electric-powered" because what else would it be?

**The Internet:** ~20 years. "Dot-com" was a category. "Cyber" was a prefix. "Internet companies" were distinct from regular companies. We capitalized "Internet" like a proper noun. We hyphenated "e-mail." People debated whether online shopping would ever work, whether anyone would do banking on a computer, whether kids were being ruined by screens. By 2015, that discourse was exhausted. Every company was an internet company or it wasn't a company.

**Mobile:** ~10 years. "Mobile apps" versus desktop apps. "Mobile-first design." Debates about whether phones would replace computers, whether constant connectivity was healthy, whether anyone would type on glass. By 2017, apps were assumed to be mobile. The modifier became redundant.

Each wave faster than the last. The half-life of disruption discourse is shrinking.

## The Pattern

Disruption discourse ends when you stop needing to specify the technology.

"AI-powered" will sound as quaint as "internet-enabled" — a modifier from a time when the technology was novel enough to mention. Eventually, software will just be... intelligent. The way software is just connected now. The way cameras are just digital now.

If the pattern holds: 5-7 years. By the early 2030s, "AI" might feel like "cyber" does today — a retro prefix from a more excitable time.

But I'm less certain about this than I sound. The pattern might not hold this time.

## But What About the Jobs?

Here's where it gets heavy: previous technologies displaced jobs gradually enough that we could pretend it wasn't happening. AI is faster, and that's *scary*.

I wrote about this in [[The SaaSpocalypse|my SaaS piece]]: Microsoft's new AI exec says they're "ichiban" with a team of mostly models. Salesforce hired no software engineers in 2025. The CEO of Anthropic predicts "all code" will be AI-written within a year.

The fear isn't irrational. But here's what I keep noticing: we had the same fears about every previous wave, and we stopped talking about them. Not because they were resolved — because we got tired.

The auto workers who lost jobs to robots didn't get them back. We just stopped making op-eds about it. The retail workers displaced by e-commerce are still displaced. We just moved on to other conversations.

The discourse ending doesn't mean the problems end. It means we normalize them.

That's uncomfortable to sit with. I don't have a neat resolution for it.

## The Agentic Difference?

One counterargument: AI is different because it's *agentic*.

Electricity didn't have opinions. The internet didn't draft your emails. Previous technologies were powerful but passive — they did what you told them, amplified your intent, extended your reach.

AI does things. It generates, decides, acts. It has something like judgment, even if it's borrowed from training data. That's new.

Does that keep it salient longer? When the tool isn't just a tool but a collaborator — or a competitor — maybe we keep talking about it?

Maybe. But I remember when people said the same thing about the internet. "It's different because it connects everyone!" "Information wants to be free!" "This changes the nature of human relationships!"

They were right. And we stopped talking about it anyway.

## The Thinking Partner Paradox

Here's what feels genuinely different to me: previous transitions happened at *human-thinking speed*.

We debated the internet's implications using memos and meetings. We figured out mobile through a decade of trial and error. The discourse unfolded at the pace of human cognition and human institutions.

This transition has a thinking partner.

I'm using AI to write this piece about AI. You might be using AI to process it. We're using the disruption to understand the disruption. AI doesn't just change the world — it helps us think through what the change means, in real time, at scale.

Which could mean the discourse phase is *compressed* — we figure out the implications faster because we have help thinking. Or it could mean the discourse is *amplified* — more takes, more angles, more confusion, more noise.

Probably both simultaneously? I honestly don't know.

And there's still so much that needs to settle. What does education look like when students have AI tutors and AI can write their essays? What does knowledge work look like when the "knowledge" part is increasingly commoditized? These aren't questions we're tired of because we've answered them. We're tired because they're genuinely hard and the ground keeps shifting.

But maybe — just maybe — AI-as-thinking-partner shortens its own half-life. We might reach the "just how things work" phase faster than any previous transition, precisely because we have help getting there.

I find that possibility both exciting and a little melancholy.

## When the Tool Disappears

We don't discuss "spell-check powered writing." Spell check is just... there. Invisible.

We don't discuss "auto-complete assisted communication." Predictive text is assumed.

We don't discuss "algorithm-curated feeds." That's just how social media works.

AI is following the same path. Not because it's less transformative — but because transformation, once complete, stops being news.

## My Guess

We stop talking about AI when:

1. **The modifier drops.** "AI-generated" → "generated." "AI-assisted" → just... how you work. This is already happening in some contexts.

2. **The absence is notable.** Instead of flagging AI use, we'll flag non-AI use. "Made without AI" will be the artisanal marker, like "hand-crafted" or "organic."

3. **The discourse exhausts itself.** We're close — can you feel it? The think pieces are blurring together. The debates are circular. The takes are recycled. Soon, writing about AI will feel like writing about "the internet" in 2020 — technically accurate but weirdly dated.

4. **New disruption arrives.** Something else will demand our attention. Biotech? Climate tech? Quantum? Something we're not tracking yet? The discourse doesn't end — it migrates.

We're probably 3-5 years from the modifier dropping in casual use. Maybe 5-7 years from "AI" feeling dated as a category.

And then we'll find the next thing to obsess over while the actual changes — the job displacement, the power concentration, the creative disruption — continue quietly in the background, no longer interesting enough to discuss.

I'm not sure if that's pessimistic or realistic. Maybe both.

---

*Written in 2026, when "AI" was still a thing you said out loud. When we were still tired but not yet bored. Check back in 2030 and see if this aged — I'm curious too.*
