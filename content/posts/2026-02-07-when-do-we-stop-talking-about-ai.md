---
title: "When Do We Stop Talking About AI?"
date: 2026-02-07T21:00
type: post
schemaVersion: 1
description: "Every disruptive technology eventually becomes invisible. The discourse ends. The modifier drops. When does that happen with AI?"
tags:
  - ai
  - culture
heroImage: /images/posts/when-stop-talking-ai-hero.png
---

I asked an AI to help me outline this essay. It gave me three angles: the historical pattern (electricity, internet, mobile — you know the one), the labor displacement angle, and the "taste becomes the new moat" argument.

I'd already read all three. I'd read them dozens of times, in dozens of pieces, some of which I'd written myself.

The tool didn't help me think. It helped me think faster about things I'd already thought.

That moment — not the discourse, but the recursive blur of it — is what I can't stop sitting with.

---

Here's what nobody talks about when they talk about AI fatigue.

The exhaustion isn't coming from repetition. It's coming from velocity.

Previous technology debates wore people down slowly. You'd hear the same arguments about the internet recycled across years of magazine covers and conference panels until one day you realized you'd stopped caring. The repetition was the mechanism. Say something enough times and it becomes background noise.

This is different. The arguments aren't just repetitive — they're accelerating. I encounter the optimistic take and the pessimistic take and the carefully "nuanced" take that splits the difference, and then I encounter them again, slightly remixed, before I've finished processing the first round. The think pieces aren't blurring together because we've been having the conversation too long. They're blurring because we're having it too fast.

And the tool is doing this to us. AI is fluent enough to generate the discourse about itself — to produce the enthusiasm and the skepticism and the exhaustion and the commentary on the exhaustion. The loop is becoming self-sustaining. Not people debating a technology, but a technology participating in its own debate, spinning the flywheel faster than human attention can track.

I don't know what to do with that. I don't think anyone does. We've never had a disruption that could narrate itself.

---

I want to tell you a small, specific thing that happened to me last month.

I was reading a thread about creative workers being displaced by generative tools — illustrators, copywriters, junior designers. The kind of thread that would have made my stomach drop a year ago. And I noticed I was skimming.

Not because the stories weren't real or the people weren't suffering. Because I'd read this thread before. Or something close enough that my nervous system couldn't tell the difference.

That's the part that unsettles me. Not the displacement itself, but the moment I caught myself normalizing it. The shrug that arrived before I'd decided to shrug.

I think this is how discourse actually dies. Not through resolution — we never resolve these debates. Not even through boredom, exactly. Through a kind of saturation where your emotional bandwidth for a topic quietly fills up and the new information just runs off the surface. You're still aware of it. You just can't feel it anymore.

And here's what makes this different from, say, getting numb to news cycles: my own exhaustion is part of the mechanism. The more tired I get of the conversation, the less resistance I offer to the changes happening underneath it. The normalization isn't something that happens *to* the discourse. It's something the discourse *does*, and my fatigue is a load-bearing part of the structure.

I'm watching this happen to me in real time. I'm participating in it by writing about it. I don't think being aware of it changes anything, which is its own kind of vertigo.

---

People keep reaching for the historical analogies. Electricity took thirty years to become invisible. The internet compressed the same arc into twenty. Mobile did it in ten. If the pattern holds, "AI-powered" will sound as dated as "internet-enabled" by the early 2030s.

I used to find that framing reassuring. The pattern says this will all settle down. The modifier will drop. We'll stop capitalizing it.

But the pattern assumed the technology and the discourse about the technology were separate things. Humans debated electricity using letters and newspapers. We debated the internet using the internet, which was weird but manageable — the tool sped up distribution but humans still did the thinking.

This time the tool is doing some of the thinking. We're using AI to process the implications of AI, to write the analyses, to generate the counterarguments, to summarize the summaries. Fish discussing water, except the water is also writing some of the discussion.

I genuinely don't know what that does to the timeline. Maybe it compresses the discourse phase — we reach the implications faster because we have help reasoning through them. Maybe it stretches it — more takes, more angles, more noise, the same circular debates spinning at higher RPM without ever gaining traction. Probably both at once, which is not a satisfying answer but might be the honest one.

---

What I keep circling back to is the texture of the complicity.

The auto workers who lost jobs to robots in the 1980s didn't get them back. We just stopped writing op-eds about it. The loss became a background condition — something everyone knew about, nobody discussed, and policy mostly ignored. The conversation didn't end because the problem was solved. It ended because the problem aged out of novelty.

I watch this process beginning now with creative displacement, with the junior roles disappearing from tech companies, with the restructuring that's happening quietly while the loud debate focuses on whether the models can really reason. And I can feel myself beginning to let it recede. Not because I've decided it doesn't matter. Because I'm tired, and there are only so many hours in a day, and the thread I'd need to read to stay current was probably half-written by the thing I'm supposed to be worried about.

The uncomfortable truth is that normalization doesn't require your consent. It just requires your bandwidth to run out. And the faster the discourse spins, the faster the bandwidth depletes.

---

I don't have a neat ending for this.

I started writing it thinking I'd arrive at something — a framework, a prediction, at minimum a useful reframe. I haven't.

What I have is this: we are living through the first technological disruption that can participate in the conversation about itself. That participation is accelerating the discourse to a speed that exhausts human attention. And that exhaustion is the mechanism by which the disruption becomes normal — not accepted, not understood, just no longer remarkable.

We'll stop talking about AI the same way we stopped talking about everything else. Not because it stopped mattering but because we got tired. The difference is that this time, the thing we're getting tired of is helping us get tired of it.

I don't know when the modifier drops. I don't know when "AI" starts to sound like "cyber" — a retro prefix from a more excitable era. But I know that when it happens, the questions we couldn't answer won't have been answered. They'll just have become the conditions we live in.

And our fatigue will have been load-bearing all the way down.

---

*Written in 2026, while the loop was still visible.*
