---
title: "When Do We Stop Talking About AI?"
date: 2026-02-07T21:00
type: post
schemaVersion: 1
description: "The specific exhaustion of a generation that can feel the stitch where human thinking and machine fluency got sewn together."
tags:
  - ai
  - culture
heroImage: /images/posts/when-stop-talking-ai-hero.png
---

This is the third major revision of this essay in a week.

The first draft came fast. I used AI to help outline it, and within an hour I had something that sounded right — clean structure, solid analogies, a confident arc from observation to insight. It read like a good essay.

The problem was I didn't believe it. Not because it was wrong, but because I couldn't tell if it was what I actually thought or just what sounded like what I thought. So I rewrote it.

The second version was closer — more honest in places, sharper in others. But there was still something off, a gap between what was on the page and what I was trying to say, and I couldn't locate it until I talked it through with a friend who asked a question the essay hadn't considered.

Now I'm on version three. I think this is closer. I'm still not sure.

This is the actual experience of writing with AI, and it's nothing like the way people describe it. It's not an identity crisis about authorship. It's not "where does my thinking end and the machine's begin?" You know what's yours. You changed the words.

What it is, is a specific kind of grind: the tool gets you to *adequate* almost instantly, and then you spend days trying to push past adequate to *true*. Past "sounds right" to "is right." And that gap — between fluent and honest — turns out to be where all the work lives.

That gap is what I want to talk about. Because I think it's the same gap that's making everyone tired.

---

Not tired of AI. I want to be clear about that. I'm not tired of the tools or the possibilities or the daily surprise of watching something genuinely new take shape.

I'm tired of a specific thing that doesn't have a name yet — the persistent, low-grade cognitive effort of using a tool that operates in the same domain as your own thinking.

Every previous technology became invisible once it worked well enough. You don't think about a hammer while hammering. You don't think about electricity while making toast. The tool recedes into the act it enables, and eventually the act is all that's left. That's how technologies stop being topics and start being infrastructure. It's why we stopped talking about electricity, the internet, mobile. The modifier dropped because the tool disappeared. *E-mail* became email. *The Internet* lost its capital. *Cyber-* stopped being a prefix. The novelty faded into the ordinary.

AI hasn't disappeared. And I think the reason is almost stupidly simple: AI works in the domain of cognition — writing, reasoning, analyzing — and you think in that same domain. A hammer doesn't resemble the hand that holds it. AI resembles the mind that uses it.

So every time you use it, some part of your attention is doing quality control not on the output but on the *thinking* — is this what I actually mean, or is it what the tool thinks I should mean? Is this my reasoning or a plausible version of my reasoning?

That monitoring is the fatigue. Not the hot takes. Not the discourse. The quiet, repetitive work of telling the difference between "sounds right" and "is right," dozens of times a day, with a tool that is extremely good at the former and has no concept of the latter.

---

I notice it most when I'm writing, but it's not only writing.

It's the meeting where someone presents an AI-drafted strategy and you can feel that it's coherent but you can't tell if it's *true* — if it reflects what the team actually knows or just what a plausible strategy document sounds like. It's the moment you read an AI-assisted email and realize you're spending more effort evaluating its tone than you would have spent just writing the thing yourself. It's the small, accumulating friction of a tool that's always fluent and never quite honest.

With every other tool I've adopted, there was a period of awkward visibility followed by transparency. I remember being aware of Google as a tool — opening a browser, typing a query, evaluating results. Now I just know things, and some of those things came from search and some from memory, and I can't tell the difference. Google became invisible. It merged with the feeling of knowing.

AI is trying to do the same thing with the feeling of *thinking*. And it's close enough to create the uncanny valley but not close enough to cross it. The output is almost right but not quite. And "not quite" is expensive, because catching it requires the exact kind of careful, slow judgment that the tool was supposed to save you from needing.

---

Here's where I have to be honest with myself, though: I don't think this is permanent.

The gap I'm describing — between fluent and true — depends on having a baseline. I know what my unassisted thinking feels like. I have decades of experience reasoning and writing without a thinking partner, and that experience is what lets me detect when something sounds right but isn't.

Take away the baseline, and the gap becomes undetectable. Not because it closes, but because no one remembers the other side.

Which is exactly what will happen generationally.

Kids growing up with AI as a default collaborator won't feel this friction. They'll never have established a sense of what "thinking without AI" feels like, any more than they have a feel for "navigating without GPS" or "researching without search engines." The tool will feel native from the start.

You can't notice a seam if you never knew the fabric was two pieces.

This has happened before. People who grew up with smartphones don't feel the boundary between "online" and "offline" that felt so fundamental to those of us who remember dial-up. That boundary was real and consequential and for a while it seemed like it would define everything. Now it's invisible to a generation that never experienced it.

The internet didn't change. The baseline shifted.

AI will follow the same path. Not because the tool gets better at mimicking our thinking. Because the people using it won't have a "before" to compare it to.

---

And this is the thing I keep landing on.

The fatigue isn't about AI. It's about being the transitional generation.

The ones who can feel the seam between AI-assisted thinking and unassisted thinking — and who can also see that this feeling is temporary. That the next generation will collaborate with AI the way we collaborate with search: seamlessly, unremarkably, without the constant micro-friction of checking whether the output matches what we actually believe.

That's a specific kind of tired. Not the exhaustion of too many think pieces or too much change. The exhaustion of perceiving a gap that you know is generational, not fundamental. Of doing the slow work of distinguishing "sounds right" from "is right," over and over, knowing that this work will quietly stop being necessary when the people doing it no longer remember thinking any other way.

The people who argued about whether the internet would destroy deep thinking — they weren't wrong. The internet did change thinking. But their children don't experience that change as a loss because they never had the thing that was lost. The debate didn't resolve. It aged out.

The same will happen here. The questions we're asking — about what it means to think with a machine, about the difference between fluency and understanding, about whether an idea is yours if you needed help finding it — these are real questions. But they're *our* questions. Rooted in our baseline. Meaningful because we have the "before" that makes the "after" visible.

---

So when do we stop talking about AI?

Not when the technology matures. Not when the discourse exhausts itself.

We stop when the people who remember thinking without it are no longer the ones setting the terms. When the seam becomes invisible not because it closed but because no one has the reference point to feel it.

That's maybe fifteen or twenty years. One generation of professionals cycling through.

Until then, we're here. The generation that can feel the difference between "sounds right" and "is right." Getting tired not of AI but of the noticing itself — the constant, low-grade work of quality-checking our own cognition against a tool that's fluent in a way that we used to have a monopoly on.

I don't think there's a fix. It's not a problem. It's the texture of being alive during a transition in the medium of thought itself — something that has, as far as I can tell, never happened before at this speed, in this domain, with this intimacy.

The best I can offer is a name for it. Not AI fatigue. *Seam fatigue*.

The specific exhaustion of a generation that can feel the stitch where human thinking and machine fluency got sewn together — and knows the stitch will be invisible to everyone who comes after.

This is the third draft. I think it's closer now. I'm still not sure.

That's the seam.

*Written in 2026, while the seam was still visible.*
