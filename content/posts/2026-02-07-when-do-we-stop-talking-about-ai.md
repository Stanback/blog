---
title: "When Do We Stop Talking About AI?"
date: 2026-02-07T21:00
type: post
schemaVersion: 1
description: "The particular exhaustion of a generation that can feel the stitch where human cognition and machine cognition got sewn together."
tags:
  - ai
  - culture
heroImage: /images/posts/when-stop-talking-ai-hero.png
---

I asked an AI to help me outline this essay. It gave me three angles I'd already read — the historical pattern, the labor displacement argument, the "taste becomes the new moat" reframe. All perfectly adequate. All instantly forgettable.

And then I spent ten minutes editing its suggestions into something that felt like mine, not entirely sure where its thinking ended and mine began.

That ten minutes is what I want to talk about.

---

Not the discourse. Not the think pieces or the existential threads or the breathless announcements. I'm not tired of AI. I'm energized by it — by the tools, the possibilities, the daily surprise of watching something genuinely new take shape.

What I'm tired of is something smaller and harder to name: the ambient mental cost of using a tool that thinks.

Every previous technology became invisible once it worked well enough. Heidegger had a word for this — *ready-to-hand* — the idea that a tool disappears into the act it enables. You don't think about a hammer while hammering. You don't think about electricity while making toast. The tool recedes, and you're left with the task.

That recession is how technologies stop being topics and start being infrastructure. It's why we stopped talking about electricity, the internet, mobile. The modifier dropped because the tool disappeared.

AI hasn't disappeared. And I don't think it can — not for us. Not for anyone who adopted it as an adult.

The reason is almost stupidly simple once you see it: AI operates in the same medium as the thinking you would use to stop thinking about it.

A hammer works in the domain of physical force. You think in a different domain. So the hammer vanishes.

AI works in the domain of cognition — writing, reasoning, analyzing, deciding. You think in that same domain. So every time you use it, some part of your attention is monitoring the boundary between its contribution and yours. Not because anyone asked you to. Not because the discourse demands a position. Because a tool that *resembles your own thinking* cannot become cognitively invisible in the way a tool that moves atoms can.

That monitoring is the fatigue. Not the hot takes. Not the obligation to have opinions. The quiet, persistent work of navigating a seam that runs through the middle of your own thought process.

---

I notice it most when I'm writing.

I'll use AI to draft something, and then I'll reshape it — changing a word here, restructuring a paragraph there — until it feels like mine. But "feels like mine" is doing a lot of work in that sentence. What does it mean for a thought to feel like yours when you arrived at it through dialogue with a machine that was trained on millions of other people's thoughts?

The question isn't philosophical in the abstract. It's a micro-sensation I experience dozens of times a day, a tiny cognitive hiccup, like trying to remember whether you locked the door.

With every other tool I've adopted, there was a period of awkward visibility followed by transparency. I remember being conscious of Google as a tool — opening a browser, typing a query, evaluating results. Now I just *know things*, and some of those things came from search and some from memory, and I genuinely cannot tell the difference most of the time. Google became invisible. It merged with the feeling of knowing.

AI is trying to do the same thing with the feeling of *thinking*. And it's close enough to create the uncanny valley but not close enough to cross it. The output is almost me but not quite. That "not quite" is where the exhaustion lives — in the gap between what the tool produces and what I'd produce, a gap I can still perceive and therefore have to manage, every single time.

---

But here's where I have to be honest with myself: I don't think this is permanent.

The seam I feel — between my thinking and AI-assisted thinking — depends on having a baseline. I know what my unassisted writing sounds like. I know what my own reasoning feels like from the inside. I have decades of experience thinking without a thinking partner, and that experience is what makes the boundary detectable.

Take away the baseline, and the boundary dissolves.

Which is exactly what will happen generationally.

Kids growing up with AI as a default collaborator won't experience this seam. They'll never have established a feel for "thinking without AI" any more than they have a feel for "navigating without GPS" or "researching without search engines." The tool will be ready-to-hand from the start — not because it stopped operating in the domain of cognition, but because they never knew cognition without it.

You can't feel a boundary if you never knew the other side.

This has happened before, quietly. People who grew up with smartphones don't feel the separation between "online" and "offline" that felt so structurally important to those of us who remember dial-up. That boundary was real and consequential and for a while it seemed like it would define everything. Now it's invisible to a generation that never experienced the seam.

The internet didn't change. The baseline shifted.

AI will follow the same path. The tool won't become invisible by getting better at mimicking us. It'll become invisible because the people using it won't have a "before" to compare it to.

---

And this, I think, is the actual source of the exhaustion.

Not the discourse. Not the pace of change. Not even the tool itself.

It's being the transitional generation.

We're the ones who can feel the seam — who notice, every time we use AI, the little negotiation between its thinking and ours. We're also the ones who can see that this noticing is temporary. That the kids will think-with-AI the way we think-with-Google: seamlessly, unremarkably, without the micro-friction of boundary management.

And we're the ones stuck in the middle, unable to stop noticing and unable to make the noticing matter.

That's a specific kind of tired. Not the fatigue of too many think pieces. The fatigue of perceiving a cognitive boundary that you know is generational, not fundamental. Of doing the mental work of monitoring a seam that will quietly stop existing when you do.

The people who argued passionately about whether the internet would destroy deep thinking — they weren't wrong, exactly. The internet did change thinking. But their children don't experience that change as a loss because they never had the thing that was lost. The debate didn't resolve. It just aged out.

The same will happen with AI. The questions we're asking now — about what's ours and what's the machine's, about the nature of authorship and originality and authentic thought — these are real questions. But they're our questions. Rooted in our baseline. Meaningful because we have the "before" that makes the "after" visible.

---

So when do we stop talking about AI?

Not when the technology matures. Not when the discourse burns itself out. Not when some new disruption steals the spotlight.

We stop talking about AI when the people who remember thinking without it are no longer the ones setting the terms of the conversation. When the seam becomes invisible not because it closed but because no one has the reference point to see it.

That's probably fifteen to twenty years. One generation of professionals cycling through. The same rough timeline it took for "Do you have a website?" to become a nonsensical question.

Until then, we're here — the generation that feels the seam. Noticing the boundary every time we use the tool. Knowing the boundary is real. Knowing it's also temporary. Getting tired not of AI but of the noticing itself, the low-grade cognitive hum of being a person who remembers what thinking felt like before and can't quite stop comparing.

I don't think there's a fix for this. It's not a problem to solve. It's the texture of being alive during a transition in the medium of thought — something that has arguably never happened before at this speed, with this intimacy, in this domain.

The best I can offer is a name for it. Not AI fatigue. Seam fatigue.

The particular exhaustion of a generation that can feel the stitch where human cognition and machine cognition got sewn together — and knows the stitch will be invisible to everyone who comes after.

*Written in 2026, while the seam was still visible.*
